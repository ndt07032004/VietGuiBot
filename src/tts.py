from transformers import pipeline
import torch
import os
import asyncio
import soundfile as sf
from src.logger import logger


async def init_tts(config: dict):
    """
    Khá»Ÿi táº¡o TTS pipeline tá»« HuggingFace.
    Æ¯u tiÃªn: facebook/mms-tts-vie (tiáº¿ng Viá»‡t) â†’ fallback sang Bark.
    """
    model_name = config["tts"].get("model", "facebook/mms-tts-vie")
    output_dir = config["tts"].get("output_dir", "outputs/tts")
    os.makedirs(output_dir, exist_ok=True)

    try:
        logger.debug(f"ğŸ”Š Loading TTS model: {model_name}")
        tts = pipeline(
            "text-to-speech",
            model=model_name,
            device=0 if torch.cuda.is_available() else -1
        )
        logger.info(f"âœ… Loaded TTS model: {model_name}")
        return tts
    except Exception as e:
        logger.error(f"âŒ Failed to load TTS model {model_name}: {e}")
        # fallback sang Bark
        if model_name != "suno/bark-small":
            logger.info("ğŸ‘‰ Falling back to Bark (suno/bark-small)")
            config["tts"]["model"] = "suno/bark-small"
            return await init_tts(config)
        raise


async def synthesize_speech(model, text: str, output_path: str) -> str:
    """
    Táº¡o audio tá»« text tiáº¿ng Viá»‡t.
    LÆ°u file .wav Ä‘á»ƒ phÃ¡t ngay sau khi generate.
    """
    try:
        logger.debug(f"ğŸ”Š Synthesizing speech for text: {text}")
        result = model(text)

        # HuggingFace pipeline tráº£ vá» máº£ng numpy chá»©a audio
        audio = result["audio"]
        sampling_rate = result["sampling_rate"]

        # lÆ°u file wav
        sf.write(output_path, audio, sampling_rate)
        logger.info(f"âœ… TTS generated: {output_path}")
        return output_path
    except Exception as e:
        logger.error(f"TTS error: {e}")
        return None
